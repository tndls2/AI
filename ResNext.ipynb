{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOkTMoJCJWfRZGIs0sxi4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tndls2/AI/blob/main/ResNext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dYqzx3FgJqB"
      },
      "outputs": [],
      "source": [
        "# import package\n",
        "\n",
        "# model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "\n",
        "# dataset and transformation\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# display images\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# utils\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import copy\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "-2qmB_kIgPP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the FashionMNIST training and test data\n",
        "trainset = datasets.FashionMNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "testset = datasets.FashionMNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(len(trainloader))\n",
        "print(len(testloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asyWxDCagXCy",
        "outputId": "9fb20b14-5182-463b-eba5-ae4ad2ff1687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14904834.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 266819.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5073354.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5930315.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
            "\n",
            "938\n",
            "157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "참고 : https://github.com/Seonghoon-Yu/AI_Paper_Review/tree/master/Classification"
      ],
      "metadata": {
        "id": "k3xhrcQbgxhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "    Cardinality = 32 # group 수\n",
        "    Basewidth = 64 # bottleneck 채널이 64이면 group convolution의 채널은 depth가 됩니다.\n",
        "    Depth = 4 # basewidth일 때, group convolution의 채널 수\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        C = BottleNeck.Cardinality\n",
        "        D = int(BottleNeck.Depth * out_channels / BottleNeck.Basewidth)\n",
        "\n",
        "        self.conv_residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, C * D, 1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(C*D),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(C*D, C*D, 3, stride=stride, padding=1, groups=BottleNeck.Cardinality, bias=False),\n",
        "            nn.BatchNorm2d(C*D),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(C*D, out_channels * BottleNeck.expansion, 1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "        )\n",
        "\n",
        "        self.conv_shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.conv_shortcut = nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, 1, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_residual(x) + self.conv_shortcut(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yBKaGU14g3A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNext\n",
        "class ResNext(nn.Module):\n",
        "    def __init__(self, nblocks, num_classes=10, init_weights=True):\n",
        "        super().__init__()\n",
        "        self.init_weights=init_weights\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # 입력 채널 수를 1로 설정\n",
        "            nn.Conv2d(1, 64, 7, stride=2, padding=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv2 = self._make_res_block(nblocks[0], 64, 1)\n",
        "        self.conv3 = self._make_res_block(nblocks[1], 128, 2)\n",
        "        self.conv4 = self._make_res_block(nblocks[2], 256, 2)\n",
        "        self.conv5 = self._make_res_block(nblocks[3], 512, 2)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.linear = nn.Linear(512 * BottleNeck.expansion, num_classes)\n",
        "\n",
        "        # weights initialization\n",
        "        if self.init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "    def _make_res_block(self, nblock, out_channels, stride):\n",
        "        strides = [stride] + [1] * (nblock-1)\n",
        "        res_block = nn.Sequential()\n",
        "        for i, stride in enumerate(strides):\n",
        "            res_block.add_module('dens_layer_{}'.format(i), BottleNeck(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * BottleNeck.expansion\n",
        "        return res_block\n",
        "\n",
        "    # weights initialization function\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def ResNext50():\n",
        "    return ResNext([3, 4, 6, 3])"
      ],
      "metadata": {
        "id": "Qno3n4Hfg71L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNext50().to(device)\n",
        "x = torch.randn((64,1, 28, 28)).to(device)\n",
        "output = model(x)\n",
        "print('output size: ', output.size())\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hy90JNVkTr-",
        "outputId": "6e1b1dd6-4880-4a9f-d3f4-6d7b2708c776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output size:  torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print summary\n",
        "summary(model, (1, 224, 224), device=device.type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3DT35tahFq2",
        "outputId": "373886f9-7c89-4269-9776-e3aa3c3142ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 111, 111]           3,136\n",
            "       BatchNorm2d-2         [-1, 64, 111, 111]             128\n",
            "              ReLU-3         [-1, 64, 111, 111]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5          [-1, 128, 56, 56]           8,192\n",
            "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
            "              ReLU-7          [-1, 128, 56, 56]               0\n",
            "            Conv2d-8          [-1, 128, 56, 56]           4,608\n",
            "       BatchNorm2d-9          [-1, 128, 56, 56]             256\n",
            "             ReLU-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          32,768\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,640\n",
            "       BottleNeck-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-16          [-1, 128, 56, 56]             256\n",
            "             ReLU-17          [-1, 128, 56, 56]               0\n",
            "           Conv2d-18          [-1, 128, 56, 56]           4,608\n",
            "      BatchNorm2d-19          [-1, 128, 56, 56]             256\n",
            "             ReLU-20          [-1, 128, 56, 56]               0\n",
            "           Conv2d-21          [-1, 256, 56, 56]          32,768\n",
            "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
            "       BottleNeck-23          [-1, 256, 56, 56]               0\n",
            "           Conv2d-24          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
            "             ReLU-26          [-1, 128, 56, 56]               0\n",
            "           Conv2d-27          [-1, 128, 56, 56]           4,608\n",
            "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
            "             ReLU-29          [-1, 128, 56, 56]               0\n",
            "           Conv2d-30          [-1, 256, 56, 56]          32,768\n",
            "      BatchNorm2d-31          [-1, 256, 56, 56]             512\n",
            "       BottleNeck-32          [-1, 256, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          65,536\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "           Conv2d-36          [-1, 256, 28, 28]          18,432\n",
            "      BatchNorm2d-37          [-1, 256, 28, 28]             512\n",
            "             ReLU-38          [-1, 256, 28, 28]               0\n",
            "           Conv2d-39          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-40          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-41          [-1, 512, 28, 28]         131,584\n",
            "       BottleNeck-42          [-1, 512, 28, 28]               0\n",
            "           Conv2d-43          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-44          [-1, 256, 28, 28]             512\n",
            "             ReLU-45          [-1, 256, 28, 28]               0\n",
            "           Conv2d-46          [-1, 256, 28, 28]          18,432\n",
            "      BatchNorm2d-47          [-1, 256, 28, 28]             512\n",
            "             ReLU-48          [-1, 256, 28, 28]               0\n",
            "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
            "       BottleNeck-51          [-1, 512, 28, 28]               0\n",
            "           Conv2d-52          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-53          [-1, 256, 28, 28]             512\n",
            "             ReLU-54          [-1, 256, 28, 28]               0\n",
            "           Conv2d-55          [-1, 256, 28, 28]          18,432\n",
            "      BatchNorm2d-56          [-1, 256, 28, 28]             512\n",
            "             ReLU-57          [-1, 256, 28, 28]               0\n",
            "           Conv2d-58          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-59          [-1, 512, 28, 28]           1,024\n",
            "       BottleNeck-60          [-1, 512, 28, 28]               0\n",
            "           Conv2d-61          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-62          [-1, 256, 28, 28]             512\n",
            "             ReLU-63          [-1, 256, 28, 28]               0\n",
            "           Conv2d-64          [-1, 256, 28, 28]          18,432\n",
            "      BatchNorm2d-65          [-1, 256, 28, 28]             512\n",
            "             ReLU-66          [-1, 256, 28, 28]               0\n",
            "           Conv2d-67          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-68          [-1, 512, 28, 28]           1,024\n",
            "       BottleNeck-69          [-1, 512, 28, 28]               0\n",
            "           Conv2d-70          [-1, 512, 28, 28]         262,144\n",
            "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-72          [-1, 512, 28, 28]               0\n",
            "           Conv2d-73          [-1, 512, 14, 14]          73,728\n",
            "      BatchNorm2d-74          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-75          [-1, 512, 14, 14]               0\n",
            "           Conv2d-76         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-77         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-78         [-1, 1024, 14, 14]         525,312\n",
            "       BottleNeck-79         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-80          [-1, 512, 14, 14]         524,288\n",
            "      BatchNorm2d-81          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-82          [-1, 512, 14, 14]               0\n",
            "           Conv2d-83          [-1, 512, 14, 14]          73,728\n",
            "      BatchNorm2d-84          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-85          [-1, 512, 14, 14]               0\n",
            "           Conv2d-86         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-87         [-1, 1024, 14, 14]           2,048\n",
            "       BottleNeck-88         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-89          [-1, 512, 14, 14]         524,288\n",
            "      BatchNorm2d-90          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-91          [-1, 512, 14, 14]               0\n",
            "           Conv2d-92          [-1, 512, 14, 14]          73,728\n",
            "      BatchNorm2d-93          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-94          [-1, 512, 14, 14]               0\n",
            "           Conv2d-95         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-96         [-1, 1024, 14, 14]           2,048\n",
            "       BottleNeck-97         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-98          [-1, 512, 14, 14]         524,288\n",
            "      BatchNorm2d-99          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-100          [-1, 512, 14, 14]               0\n",
            "          Conv2d-101          [-1, 512, 14, 14]          73,728\n",
            "     BatchNorm2d-102          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-103          [-1, 512, 14, 14]               0\n",
            "          Conv2d-104         [-1, 1024, 14, 14]         524,288\n",
            "     BatchNorm2d-105         [-1, 1024, 14, 14]           2,048\n",
            "      BottleNeck-106         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-107          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-108          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-109          [-1, 512, 14, 14]               0\n",
            "          Conv2d-110          [-1, 512, 14, 14]          73,728\n",
            "     BatchNorm2d-111          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-112          [-1, 512, 14, 14]               0\n",
            "          Conv2d-113         [-1, 1024, 14, 14]         524,288\n",
            "     BatchNorm2d-114         [-1, 1024, 14, 14]           2,048\n",
            "      BottleNeck-115         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-116          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-117          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-118          [-1, 512, 14, 14]               0\n",
            "          Conv2d-119          [-1, 512, 14, 14]          73,728\n",
            "     BatchNorm2d-120          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-121          [-1, 512, 14, 14]               0\n",
            "          Conv2d-122         [-1, 1024, 14, 14]         524,288\n",
            "     BatchNorm2d-123         [-1, 1024, 14, 14]           2,048\n",
            "      BottleNeck-124         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-125         [-1, 1024, 14, 14]       1,048,576\n",
            "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-127         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-128           [-1, 1024, 7, 7]         294,912\n",
            "     BatchNorm2d-129           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-130           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-131           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-132           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-133           [-1, 2048, 7, 7]       2,099,200\n",
            "      BottleNeck-134           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-135           [-1, 1024, 7, 7]       2,097,152\n",
            "     BatchNorm2d-136           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-137           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-138           [-1, 1024, 7, 7]         294,912\n",
            "     BatchNorm2d-139           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-140           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-141           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-142           [-1, 2048, 7, 7]           4,096\n",
            "      BottleNeck-143           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-144           [-1, 1024, 7, 7]       2,097,152\n",
            "     BatchNorm2d-145           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-146           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-147           [-1, 1024, 7, 7]         294,912\n",
            "     BatchNorm2d-148           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-149           [-1, 1024, 7, 7]               0\n",
            "          Conv2d-150           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-151           [-1, 2048, 7, 7]           4,096\n",
            "      BottleNeck-152           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-153           [-1, 2048, 1, 1]               0\n",
            "          Linear-154                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 22,990,282\n",
            "Trainable params: 22,990,282\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 307.85\n",
            "Params size (MB): 87.70\n",
            "Estimated Total Size (MB): 395.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train&Test"
      ],
      "metadata": {
        "id": "VrFn-myNgx62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function, optimizer, lr_scheduler\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
        "\n",
        "\n",
        "# get current lr\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "# calculate the metric per mini-batch\n",
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# calculate the loss per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss_b = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "    \n",
        "    return loss_b.item(), metric_b\n",
        "\n",
        "\n",
        "# calculate the loss per epochs\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "        \n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "    return loss, metric\n",
        "\n",
        "# function to start training\n",
        "def train_val(model, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    trainloader=params['trainloader']\n",
        "    testloader=params['testloader']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, trainloader, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, testloader, sanity_check)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "Viyc4YcchIMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training parameters\n",
        "params_train = {\n",
        "    'num_epochs':100,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'trainloader':trainloader,\n",
        "    'testloader':testloader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')\n",
        "     "
      ],
      "metadata": {
        "id": "yMjPIwoyhPW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LKTwzlLmUHg",
        "outputId": "aec8d250-276f-4b07-8d03-d829aefd8ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 0.8843 min\n",
            "----------\n",
            "Epoch 1/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 1.7534 min\n",
            "----------\n",
            "Epoch 2/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 2.6266 min\n",
            "----------\n",
            "Epoch 3/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 3.4942 min\n",
            "----------\n",
            "Epoch 4/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 4.3593 min\n",
            "----------\n",
            "Epoch 5/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 5.2546 min\n",
            "----------\n",
            "Epoch 6/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 6.1389 min\n",
            "----------\n",
            "Epoch 7/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 7.0141 min\n",
            "----------\n",
            "Epoch 8/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 7.9042 min\n",
            "----------\n",
            "Epoch 9/99, current lr= 0.01\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 8.7731 min\n",
            "----------\n",
            "Epoch 10/99, current lr= 0.01\n",
            "Loading best model weights!\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 9.6483 min\n",
            "----------\n",
            "Epoch 11/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 10.5380 min\n",
            "----------\n",
            "Epoch 12/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 11.4124 min\n",
            "----------\n",
            "Epoch 13/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 12.2837 min\n",
            "----------\n",
            "Epoch 14/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 13.1657 min\n",
            "----------\n",
            "Epoch 15/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 14.0553 min\n",
            "----------\n",
            "Epoch 16/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 14.9229 min\n",
            "----------\n",
            "Epoch 17/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 15.7923 min\n",
            "----------\n",
            "Epoch 18/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 16.6789 min\n",
            "----------\n",
            "Epoch 19/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 17.5487 min\n",
            "----------\n",
            "Epoch 20/99, current lr= 0.001\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 18.4159 min\n",
            "----------\n",
            "Epoch 21/99, current lr= 0.001\n",
            "Loading best model weights!\n",
            "train loss: nan, val loss: nan, accuracy: 10.00, time: 19.2995 min\n",
            "----------\n",
            "Epoch 22/99, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.647035, val loss: 0.439125, accuracy: 84.63, time: 20.1817 min\n",
            "----------\n",
            "Epoch 23/99, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.380251, val loss: 0.372255, accuracy: 86.84, time: 21.0621 min\n",
            "----------\n",
            "Epoch 24/99, current lr= 0.0001\n",
            "train loss: 0.303344, val loss: 0.380181, accuracy: 87.07, time: 21.9512 min\n",
            "----------\n",
            "Epoch 25/99, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.257835, val loss: 0.369715, accuracy: 87.38, time: 22.8323 min\n",
            "----------\n",
            "Epoch 26/99, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.221151, val loss: 0.354352, accuracy: 88.11, time: 23.7107 min\n",
            "----------\n",
            "Epoch 27/99, current lr= 0.0001\n",
            "train loss: 0.192856, val loss: 0.369134, accuracy: 88.49, time: 24.6129 min\n",
            "----------\n",
            "Epoch 28/99, current lr= 0.0001\n",
            "train loss: 0.167614, val loss: 0.369277, accuracy: 88.36, time: 25.4896 min\n",
            "----------\n",
            "Epoch 29/99, current lr= 0.0001\n",
            "train loss: 0.151275, val loss: 0.356025, accuracy: 89.16, time: 26.3593 min\n",
            "----------\n",
            "Epoch 30/99, current lr= 0.0001\n",
            "train loss: 0.134277, val loss: 0.383704, accuracy: 89.14, time: 27.2479 min\n",
            "----------\n",
            "Epoch 31/99, current lr= 0.0001\n",
            "train loss: 0.115564, val loss: 0.395828, accuracy: 89.04, time: 28.1451 min\n",
            "----------\n",
            "Epoch 32/99, current lr= 0.0001\n",
            "train loss: 0.101767, val loss: 0.410474, accuracy: 89.16, time: 29.0170 min\n",
            "----------\n",
            "Epoch 33/99, current lr= 0.0001\n",
            "train loss: 0.088599, val loss: 0.436565, accuracy: 88.44, time: 29.8984 min\n",
            "----------\n",
            "Epoch 34/99, current lr= 0.0001\n",
            "train loss: 0.081340, val loss: 0.428744, accuracy: 89.26, time: 30.7782 min\n",
            "----------\n",
            "Epoch 35/99, current lr= 0.0001\n",
            "train loss: 0.074567, val loss: 0.471469, accuracy: 89.49, time: 31.6442 min\n",
            "----------\n",
            "Epoch 36/99, current lr= 0.0001\n",
            "train loss: 0.073457, val loss: 0.434794, accuracy: 89.50, time: 32.5191 min\n",
            "----------\n",
            "Epoch 37/99, current lr= 0.0001\n",
            "Loading best model weights!\n",
            "train loss: 0.058482, val loss: 0.489090, accuracy: 89.29, time: 33.4019 min\n",
            "----------\n",
            "Epoch 38/99, current lr= 1e-05\n",
            "Copied best model weights!\n",
            "train loss: 0.130451, val loss: 0.298710, accuracy: 89.82, time: 34.3486 min\n",
            "----------\n",
            "Epoch 39/99, current lr= 1e-05\n",
            "train loss: 0.104395, val loss: 0.298922, accuracy: 89.93, time: 35.3874 min\n",
            "----------\n",
            "Epoch 40/99, current lr= 1e-05\n",
            "train loss: 0.091266, val loss: 0.302253, accuracy: 90.19, time: 36.3256 min\n",
            "----------\n",
            "Epoch 41/99, current lr= 1e-05\n",
            "train loss: 0.080193, val loss: 0.307355, accuracy: 90.10, time: 37.2163 min\n",
            "----------\n",
            "Epoch 42/99, current lr= 1e-05\n",
            "train loss: 0.071072, val loss: 0.309463, accuracy: 90.26, time: 38.1180 min\n",
            "----------\n",
            "Epoch 43/99, current lr= 1e-05\n",
            "train loss: 0.064233, val loss: 0.316525, accuracy: 90.17, time: 39.0078 min\n",
            "----------\n",
            "Epoch 44/99, current lr= 1e-05\n",
            "train loss: 0.057979, val loss: 0.323391, accuracy: 90.30, time: 39.8986 min\n",
            "----------\n",
            "Epoch 45/99, current lr= 1e-05\n",
            "train loss: 0.052572, val loss: 0.329736, accuracy: 90.13, time: 40.7908 min\n",
            "----------\n",
            "Epoch 46/99, current lr= 1e-05\n",
            "train loss: 0.047047, val loss: 0.334317, accuracy: 90.20, time: 41.6846 min\n",
            "----------\n",
            "Epoch 47/99, current lr= 1e-05\n",
            "train loss: 0.042759, val loss: 0.338901, accuracy: 90.27, time: 42.5910 min\n",
            "----------\n",
            "Epoch 48/99, current lr= 1e-05\n",
            "train loss: 0.037750, val loss: 0.349009, accuracy: 90.25, time: 43.4741 min\n",
            "----------\n",
            "Epoch 49/99, current lr= 1e-05\n",
            "Loading best model weights!\n",
            "train loss: 0.034276, val loss: 0.352833, accuracy: 90.02, time: 44.3580 min\n",
            "----------\n",
            "Epoch 50/99, current lr= 1.0000000000000002e-06\n",
            "Copied best model weights!\n",
            "train loss: 0.104479, val loss: 0.296990, accuracy: 89.95, time: 45.2471 min\n",
            "----------\n",
            "Epoch 51/99, current lr= 1.0000000000000002e-06\n",
            "Copied best model weights!\n",
            "train loss: 0.101778, val loss: 0.296809, accuracy: 90.14, time: 46.1273 min\n",
            "----------\n",
            "Epoch 52/99, current lr= 1.0000000000000002e-06\n",
            "Copied best model weights!\n",
            "train loss: 0.100568, val loss: 0.296203, accuracy: 90.01, time: 47.0239 min\n",
            "----------\n",
            "Epoch 53/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.097152, val loss: 0.296639, accuracy: 90.09, time: 47.9051 min\n",
            "----------\n",
            "Epoch 54/99, current lr= 1.0000000000000002e-06\n",
            "Copied best model weights!\n",
            "train loss: 0.097458, val loss: 0.296179, accuracy: 90.03, time: 48.7865 min\n",
            "----------\n",
            "Epoch 55/99, current lr= 1.0000000000000002e-06\n",
            "Copied best model weights!\n",
            "train loss: 0.095376, val loss: 0.296108, accuracy: 90.02, time: 49.6749 min\n",
            "----------\n",
            "Epoch 56/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.094037, val loss: 0.296449, accuracy: 90.07, time: 50.5612 min\n",
            "----------\n",
            "Epoch 57/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.092594, val loss: 0.297450, accuracy: 90.05, time: 51.4390 min\n",
            "----------\n",
            "Epoch 58/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.091362, val loss: 0.298205, accuracy: 90.12, time: 52.3462 min\n",
            "----------\n",
            "Epoch 59/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.090129, val loss: 0.297884, accuracy: 90.09, time: 53.2634 min\n",
            "----------\n",
            "Epoch 60/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.089191, val loss: 0.299532, accuracy: 90.11, time: 54.1518 min\n",
            "----------\n",
            "Epoch 61/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.086718, val loss: 0.298745, accuracy: 90.22, time: 55.0304 min\n",
            "----------\n",
            "Epoch 62/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.086118, val loss: 0.298467, accuracy: 90.14, time: 55.9053 min\n",
            "----------\n",
            "Epoch 63/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.084659, val loss: 0.298946, accuracy: 90.13, time: 56.7721 min\n",
            "----------\n",
            "Epoch 64/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.084129, val loss: 0.300359, accuracy: 90.13, time: 57.6498 min\n",
            "----------\n",
            "Epoch 65/99, current lr= 1.0000000000000002e-06\n",
            "train loss: 0.082953, val loss: 0.302294, accuracy: 90.12, time: 58.5215 min\n",
            "----------\n",
            "Epoch 66/99, current lr= 1.0000000000000002e-06\n",
            "Loading best model weights!\n",
            "train loss: 0.080962, val loss: 0.300345, accuracy: 90.12, time: 59.3985 min\n",
            "----------\n",
            "Epoch 67/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.094250, val loss: 0.297221, accuracy: 90.00, time: 60.2809 min\n",
            "----------\n",
            "Epoch 68/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.093056, val loss: 0.297045, accuracy: 90.13, time: 61.1687 min\n",
            "----------\n",
            "Epoch 69/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.093562, val loss: 0.296981, accuracy: 90.07, time: 62.0743 min\n",
            "----------\n",
            "Epoch 70/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.092615, val loss: 0.298194, accuracy: 90.04, time: 62.9762 min\n",
            "----------\n",
            "Epoch 71/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.092619, val loss: 0.297199, accuracy: 90.06, time: 63.8768 min\n",
            "----------\n",
            "Epoch 72/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.093183, val loss: 0.297477, accuracy: 90.10, time: 64.7964 min\n",
            "----------\n",
            "Epoch 73/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.092537, val loss: 0.298975, accuracy: 90.04, time: 65.6976 min\n",
            "----------\n",
            "Epoch 74/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.093138, val loss: 0.298272, accuracy: 90.04, time: 66.5723 min\n",
            "----------\n",
            "Epoch 75/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.092474, val loss: 0.298254, accuracy: 90.11, time: 67.4491 min\n",
            "----------\n",
            "Epoch 76/99, current lr= 1.0000000000000002e-07\n",
            "train loss: 0.092232, val loss: 0.297856, accuracy: 90.12, time: 68.3256 min\n",
            "----------\n",
            "Epoch 77/99, current lr= 1.0000000000000002e-07\n",
            "Loading best model weights!\n",
            "train loss: 0.092865, val loss: 0.298305, accuracy: 90.11, time: 69.1991 min\n",
            "----------\n",
            "Epoch 78/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093958, val loss: 0.296277, accuracy: 90.16, time: 70.0767 min\n",
            "----------\n",
            "Epoch 79/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.092770, val loss: 0.297683, accuracy: 89.99, time: 70.9475 min\n",
            "----------\n",
            "Epoch 80/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093584, val loss: 0.296806, accuracy: 90.07, time: 71.8270 min\n",
            "----------\n",
            "Epoch 81/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093789, val loss: 0.297338, accuracy: 90.03, time: 72.7088 min\n",
            "----------\n",
            "Epoch 82/99, current lr= 1.0000000000000004e-08\n",
            "Copied best model weights!\n",
            "train loss: 0.093283, val loss: 0.296086, accuracy: 90.06, time: 73.5980 min\n",
            "----------\n",
            "Epoch 83/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.094481, val loss: 0.296947, accuracy: 90.01, time: 74.4881 min\n",
            "----------\n",
            "Epoch 84/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.092962, val loss: 0.298023, accuracy: 90.07, time: 75.3696 min\n",
            "----------\n",
            "Epoch 85/99, current lr= 1.0000000000000004e-08\n",
            "Copied best model weights!\n",
            "train loss: 0.093659, val loss: 0.296052, accuracy: 89.99, time: 76.2436 min\n",
            "----------\n",
            "Epoch 86/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093325, val loss: 0.297325, accuracy: 90.03, time: 77.1152 min\n",
            "----------\n",
            "Epoch 87/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093462, val loss: 0.296865, accuracy: 90.03, time: 78.0120 min\n",
            "----------\n",
            "Epoch 88/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093614, val loss: 0.298438, accuracy: 89.98, time: 78.8836 min\n",
            "----------\n",
            "Epoch 89/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.095073, val loss: 0.296118, accuracy: 90.09, time: 79.7508 min\n",
            "----------\n",
            "Epoch 90/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093843, val loss: 0.296969, accuracy: 90.02, time: 80.6283 min\n",
            "----------\n",
            "Epoch 91/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093550, val loss: 0.297899, accuracy: 90.02, time: 81.5020 min\n",
            "----------\n",
            "Epoch 92/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093665, val loss: 0.297673, accuracy: 90.03, time: 82.3656 min\n",
            "----------\n",
            "Epoch 93/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.094426, val loss: 0.296574, accuracy: 90.12, time: 83.2318 min\n",
            "----------\n",
            "Epoch 94/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.092940, val loss: 0.296701, accuracy: 90.10, time: 84.1197 min\n",
            "----------\n",
            "Epoch 95/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093664, val loss: 0.296839, accuracy: 90.09, time: 84.9951 min\n",
            "----------\n",
            "Epoch 96/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093702, val loss: 0.299781, accuracy: 89.96, time: 85.8635 min\n",
            "----------\n",
            "Epoch 97/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.093402, val loss: 0.297174, accuracy: 90.08, time: 86.7446 min\n",
            "----------\n",
            "Epoch 98/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.094099, val loss: 0.298207, accuracy: 90.09, time: 87.6238 min\n",
            "----------\n",
            "Epoch 99/99, current lr= 1.0000000000000004e-08\n",
            "train loss: 0.094271, val loss: 0.298026, accuracy: 90.12, time: 88.4830 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "W4lbNGcjnGQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train-val progress\n",
        "num_epochs = params_train['num_epochs']\n",
        "\n",
        "# plot loss progress\n",
        "plt.title('Train-Val Loss')\n",
        "plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy progress\n",
        "plt.title('Train-Val Accuracy')\n",
        "plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "Yzse5JithPVp",
        "outputId": "0e770b99-9d00-4b4f-f5d7-63c99a6fa975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 정확도를 추적할 변수 초기화\n",
        "top1_correct = 0\n",
        "top5_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "# 테스트 데이터셋을 사용하여 정확도 계산\n",
        "model.eval()  # 평가 모드로 설정\n",
        "\n",
        "with torch.no_grad():  # 그래디언트 추적 비활성화\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 모델에 입력 데이터 전달\n",
        "        outputs = model(images)\n",
        "\n",
        "        # top-1 및 top-5 예측 추출\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        _, top5_predicted = torch.topk(outputs, 5, dim=1)\n",
        "\n",
        "        # 정확한 예측 수 계산\n",
        "        top1_correct += (predicted == labels).sum().item()\n",
        "        top5_correct += sum(labels[i] in top5_predicted[i] for i in range(len(labels)))\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "# 정확도 계산\n",
        "top1_accuracy = top1_correct / total_samples\n",
        "top5_accuracy = top5_correct / total_samples\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Top-1 Accuracy: {top1_accuracy * 100:.2f}%\")\n",
        "print(f\"Top-5 Accuracy: {top5_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6zjZmB2zlwi",
        "outputId": "cf99e690-b739-49d1-dc7d-f57b5f697569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 Accuracy: 89.99%\n",
            "Top-5 Accuracy: 99.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So6tDnCQzqep",
        "outputId": "b5950314-8df6-4d2a-a816-853311f18970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.7-py3-none-any.whl size=11076 sha256=075907348fb8dab5d7b7f680e63f6596af70d8b117b58d4a4a2c832a3aa4ec82\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/54/3b/f84523431ce82e08462644d279c0e13a51a00236e237e6bc7e\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "    net = model\n",
        "    macs, params = get_model_complexity_info(net, (1, 224, 224), as_strings=True,\n",
        "                                             print_per_layer_stat=True, verbose=True)\n",
        "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGUAUbKdzsO_",
        "outputId": "3dfc3e26-cf1a-4b88-a300-a36c34497336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module BottleNeck is treated as a zero-op.\n",
            "Warning: module ResNext is treated as a zero-op.\n",
            "ResNext(\n",
            "  22.99 M, 100.000% Params, 4.18 GMac, 100.000% MACs, \n",
            "  (conv1): Sequential(\n",
            "    3.26 k, 0.014% Params, 41.79 MMac, 0.999% MACs, \n",
            "    (0): Conv2d(3.14 k, 0.014% Params, 38.64 MMac, 0.923% MACs, 1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(128, 0.001% Params, 1.58 MMac, 0.038% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(0, 0.000% Params, 788.54 KMac, 0.019% MACs, )\n",
            "    (3): MaxPool2d(0, 0.000% Params, 788.54 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    205.57 k, 0.894% Params, 647.07 MMac, 15.463% MACs, \n",
            "    (dens_layer_0): BottleNeck(\n",
            "      63.23 k, 0.275% Params, 199.1 MMac, 4.758% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        46.59 k, 0.203% Params, 146.92 MMac, 3.511% MACs, \n",
            "        (0): Conv2d(8.19 k, 0.036% Params, 25.69 MMac, 0.614% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (3): Conv2d(4.61 k, 0.020% Params, 14.45 MMac, 0.345% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (6): Conv2d(32.77 k, 0.143% Params, 102.76 MMac, 2.456% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.038% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Conv2d(16.64 k, 0.072% Params, 52.18 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (dens_layer_1): BottleNeck(\n",
            "      71.17 k, 0.310% Params, 223.99 MMac, 5.353% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        71.17 k, 0.310% Params, 223.99 MMac, 5.353% MACs, \n",
            "        (0): Conv2d(32.77 k, 0.143% Params, 102.76 MMac, 2.456% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (3): Conv2d(4.61 k, 0.020% Params, 14.45 MMac, 0.345% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (6): Conv2d(32.77 k, 0.143% Params, 102.76 MMac, 2.456% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.038% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_2): BottleNeck(\n",
            "      71.17 k, 0.310% Params, 223.99 MMac, 5.353% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        71.17 k, 0.310% Params, 223.99 MMac, 5.353% MACs, \n",
            "        (0): Conv2d(32.77 k, 0.143% Params, 102.76 MMac, 2.456% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (3): Conv2d(4.61 k, 0.020% Params, 14.45 MMac, 0.345% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (6): Conv2d(32.77 k, 0.143% Params, 102.76 MMac, 2.456% MACs, 128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.038% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    1.2 M, 5.205% Params, 1.1 GMac, 26.183% MACs, \n",
            "    (dens_layer_0): BottleNeck(\n",
            "      348.67 k, 1.517% Params, 429.71 MMac, 10.269% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        217.09 k, 0.944% Params, 326.55 MMac, 7.804% MACs, \n",
            "        (0): Conv2d(65.54 k, 0.285% Params, 205.52 MMac, 4.911% MACs, 256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.038% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, )\n",
            "        (3): Conv2d(18.43 k, 0.080% Params, 14.45 MMac, 0.345% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (6): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Conv2d(131.58 k, 0.572% Params, 103.16 MMac, 2.465% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "    )\n",
            "    (dens_layer_1): BottleNeck(\n",
            "      282.62 k, 1.229% Params, 221.98 MMac, 5.305% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        282.62 k, 1.229% Params, 221.98 MMac, 5.305% MACs, \n",
            "        (0): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (3): Conv2d(18.43 k, 0.080% Params, 14.45 MMac, 0.345% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (6): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_2): BottleNeck(\n",
            "      282.62 k, 1.229% Params, 221.98 MMac, 5.305% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        282.62 k, 1.229% Params, 221.98 MMac, 5.305% MACs, \n",
            "        (0): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (3): Conv2d(18.43 k, 0.080% Params, 14.45 MMac, 0.345% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (6): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_3): BottleNeck(\n",
            "      282.62 k, 1.229% Params, 221.98 MMac, 5.305% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        282.62 k, 1.229% Params, 221.98 MMac, 5.305% MACs, \n",
            "        (0): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (3): Conv2d(18.43 k, 0.080% Params, 14.45 MMac, 0.345% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (6): Conv2d(131.07 k, 0.570% Params, 102.76 MMac, 2.456% MACs, 256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    7.02 M, 30.541% Params, 1.53 GMac, 36.622% MACs, \n",
            "    (dens_layer_0): BottleNeck(\n",
            "      1.39 M, 6.044% Params, 427.6 MMac, 10.218% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        864.26 k, 3.759% Params, 324.64 MMac, 7.758% MACs, \n",
            "        (0): Conv2d(262.14 k, 1.140% Params, 205.52 MMac, 4.911% MACs, 512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 401.41 KMac, 0.010% MACs, )\n",
            "        (3): Conv2d(73.73 k, 0.321% Params, 14.45 MMac, 0.345% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (6): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Conv2d(525.31 k, 2.285% Params, 102.96 MMac, 2.460% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "    )\n",
            "    (dens_layer_1): BottleNeck(\n",
            "      1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (3): Conv2d(73.73 k, 0.321% Params, 14.45 MMac, 0.345% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (6): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_2): BottleNeck(\n",
            "      1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (3): Conv2d(73.73 k, 0.321% Params, 14.45 MMac, 0.345% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (6): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_3): BottleNeck(\n",
            "      1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (3): Conv2d(73.73 k, 0.321% Params, 14.45 MMac, 0.345% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (6): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_4): BottleNeck(\n",
            "      1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (3): Conv2d(73.73 k, 0.321% Params, 14.45 MMac, 0.345% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (6): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_5): BottleNeck(\n",
            "      1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        1.13 M, 4.899% Params, 220.98 MMac, 5.281% MACs, \n",
            "        (0): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (3): Conv2d(73.73 k, 0.321% Params, 14.45 MMac, 0.345% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 100.35 KMac, 0.002% MACs, )\n",
            "        (6): Conv2d(524.29 k, 2.280% Params, 102.76 MMac, 2.456% MACs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    14.54 M, 63.257% Params, 867.49 MMac, 20.731% MACs, \n",
            "    (dens_layer_0): BottleNeck(\n",
            "      5.55 M, 24.132% Params, 426.55 MMac, 10.193% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        3.45 M, 15.001% Params, 323.69 MMac, 7.735% MACs, \n",
            "        (0): Conv2d(1.05 M, 4.561% Params, 205.52 MMac, 4.911% MACs, 1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2.05 k, 0.009% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.005% MACs, )\n",
            "        (3): Conv2d(294.91 k, 1.283% Params, 14.45 MMac, 0.345% MACs, 1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(2.05 k, 0.009% Params, 100.35 KMac, 0.002% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 50.18 KMac, 0.001% MACs, )\n",
            "        (6): Conv2d(2.1 M, 9.122% Params, 102.76 MMac, 2.456% MACs, 1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(4.1 k, 0.018% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Conv2d(2.1 M, 9.131% Params, 102.86 MMac, 2.458% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
            "    )\n",
            "    (dens_layer_1): BottleNeck(\n",
            "      4.5 M, 19.562% Params, 220.47 MMac, 5.269% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        4.5 M, 19.562% Params, 220.47 MMac, 5.269% MACs, \n",
            "        (0): Conv2d(2.1 M, 9.122% Params, 102.76 MMac, 2.456% MACs, 2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2.05 k, 0.009% Params, 100.35 KMac, 0.002% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 50.18 KMac, 0.001% MACs, )\n",
            "        (3): Conv2d(294.91 k, 1.283% Params, 14.45 MMac, 0.345% MACs, 1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(2.05 k, 0.009% Params, 100.35 KMac, 0.002% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 50.18 KMac, 0.001% MACs, )\n",
            "        (6): Conv2d(2.1 M, 9.122% Params, 102.76 MMac, 2.456% MACs, 1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(4.1 k, 0.018% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "    (dens_layer_2): BottleNeck(\n",
            "      4.5 M, 19.562% Params, 220.47 MMac, 5.269% MACs, \n",
            "      (conv_residual): Sequential(\n",
            "        4.5 M, 19.562% Params, 220.47 MMac, 5.269% MACs, \n",
            "        (0): Conv2d(2.1 M, 9.122% Params, 102.76 MMac, 2.456% MACs, 2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2.05 k, 0.009% Params, 100.35 KMac, 0.002% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(0, 0.000% Params, 50.18 KMac, 0.001% MACs, )\n",
            "        (3): Conv2d(294.91 k, 1.283% Params, 14.45 MMac, 0.345% MACs, 1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "        (4): BatchNorm2d(2.05 k, 0.009% Params, 100.35 KMac, 0.002% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(0, 0.000% Params, 50.18 KMac, 0.001% MACs, )\n",
            "        (6): Conv2d(2.1 M, 9.122% Params, 102.76 MMac, 2.456% MACs, 1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(4.1 k, 0.018% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv_shortcut): Sequential(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))\n",
            "  (linear): Linear(20.49 k, 0.089% Params, 20.49 KMac, 0.000% MACs, in_features=2048, out_features=10, bias=True)\n",
            ")\n",
            "Computational complexity:       4.18 GMac\n",
            "Number of parameters:           22.99 M \n"
          ]
        }
      ]
    }
  ]
}